# âœ… ì™„ì„±ë³¸ youtube_automation.py (ë³µë¶™í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥)
# ê¸°ëŠ¥: ê³ ì •ëŒ“ê¸€ â†’ ë”ë³´ê¸°ë€ â†’ ìŠ¤í¬ë¦½íŠ¸ ìˆœì„œë¡œ Sonar ë¶„ì„ + ì¶œì²˜ í¬í•¨ + ì¤‘ë³µ ê²€ì‚¬ + ê¸´ì˜ìƒ

import json  
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
import requests
import logging
import sys
import os
from dotenv import load_dotenv
import re
from datetime import datetime

log_date = datetime.now().strftime("%Y-%m-%d")
log_path = f"logs/menu_extraction_{log_date}.log"

# ë¡œê·¸ + í„°ë¯¸ë„ ë™ì‹œ ì¶œë ¥
logging.basicConfig(
    filename=log_path,
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
)


class DualLogger:
    def __init__(self):
        self.terminal = sys.__stdout__
    def write(self, message):
        self.terminal.write(message)
        logging.info(message.strip())
    def flush(self):
        self.terminal.flush()
sys.stdout = DualLogger()

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
API_KEY = os.getenv("YOUTUBE_API_KEY")
SONAR_API_KEY = os.getenv("SONAR_API_KEY")
CHANNEL_ID = "UC2IIBYSTMSvJaK2UJzCC06g"  # ì›í•˜ëŠ” ì±„ë„ë¡œ êµì²´ ê°€ëŠ¥

def extract_json_block(text):
    try:
        match = re.search(r'\{[\s\S]*?\}', text)
        if match:
            parsed = json.loads(match.group())
            if "ë©”ë‰´" in parsed and "ì¬ë£Œ" in parsed:
                return parsed
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
    return None

def append_to_js(parsed_data, video_url, uploader_name, upload_date, file_path="src/menuData_kr.js"):
    try:
        entry = {
            "name": parsed_data["ë©”ë‰´"],
            "url": video_url,
            "uploader": uploader_name,
            "upload_date": upload_date,
            "ingredients": parsed_data["ì¬ë£Œ"],
            "source": parsed_data.get("ì¶œì²˜", "unknown")
        }

        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
            existing_items = re.findall(r"\{[\s\S]*?\}", content)
            for item in existing_items:
                try:
                    data = json.loads(item)
                    if data.get("name") == entry["name"] and data.get("url") == entry["url"]:
                        print("âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í•­ëª© (ì¤‘ë³µ) â†’ ì¶”ê°€ ìƒëµ")
                        return
                except:
                    continue
            lines = content.splitlines()

        close_idx = next((i for i, line in reversed(list(enumerate(lines))) if line.strip() == "];"), -1)
        export_idx = next((i for i, line in reversed(list(enumerate(lines))) if "export default" in line), -1)
        if close_idx == -1 or export_idx == -1:
            print("âŒ JS í˜•ì‹ ì´ìƒ")
            return

        insert_idx = 1
        lines.insert(insert_idx, json.dumps(entry, ensure_ascii=False, indent=2) + ",\n")
        with open(file_path, "w", encoding="utf-8") as f:
            f.writelines(line + "\n" for line in lines)

        print(f"âœ… ë°ì´í„° ì¶”ê°€ ì™„ë£Œ (ì¶œì²˜: {entry['source']})")
    except Exception as e:
        print("âŒ JS ì €ì¥ ì¤‘ ì˜¤ë¥˜:", e)

def initialize_js_file_if_needed(file_path="src/menuData_kr.js"):
    if not os.path.exists(file_path):
        with open(file_path, "w", encoding="utf-8") as f:
            f.write("const menuData_kr = [\n];\n\nexport default menuData_kr;\n")
    else:
        with open(file_path, "r", encoding="utf-8") as f:
            lines = f.readlines()

        new_lines = []
        seen_export = False
        for line in lines:
            if "export default" in line:
                if not seen_export:
                    seen_export = True
                    new_lines.append(line)
            else:
                new_lines.append(line)

        with open(file_path, "w", encoding="utf-8") as f:
            f.writelines(new_lines)

def finalize_js_file(file_path="src/menuData_kr.js"):
    try:
        with open(file_path, "r+", encoding="utf-8") as f:
            content = f.read().rstrip(",\n")
            f.seek(0)
            f.write(content)
            f.truncate()
        print("ğŸ“ JS íŒŒì¼ ì¢…ë£Œ êµ¬ë¬¸ ì¶”ê°€ ì™„ë£Œ")
    except Exception as e:
        print("âŒ ì¢…ë£Œ êµ¬ë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨:", e)


def get_video_ids_and_channel(api_key, channel_id, max_results=0):
    youtube = build("youtube", "v3", developerKey=api_key)
    videos = []

    search_response = youtube.search().list(
        channelId=channel_id,
        part="id",
        order="date",
        maxResults=max_results,
        type="video"
    ).execute()

    video_ids = [item["id"]["videoId"] for item in search_response["items"]]
    video_response = youtube.videos().list(
        part="snippet,contentDetails",
        id=",".join(video_ids)
    ).execute()

    for item in video_response["items"]:
        if item["snippet"]["liveBroadcastContent"] != "none":
            continue  # ìƒë°©ì†¡/ì˜ˆì•½ ë°©ì†¡ ì œì™¸

        # â± ê¸¸ì´ ì œí•œ ì¶”ê°€ (PT##M##S í˜•ì‹ â†’ ì´ˆ ë³€í™˜)
        duration = item["contentDetails"]["duration"]
        match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
        hours = int(match.group(1) or 0)
        minutes = int(match.group(2) or 0)
        seconds = int(match.group(3) or 0)
        total_seconds = hours * 3600 + minutes * 60 + seconds

        if total_seconds >= 50 * 60:
            print(f"â© {item['id']} â†’ ì˜ìƒ ê¸¸ì´ {total_seconds//60}ë¶„ â†’ ê±´ë„ˆëœ€")
            continue

        videos.append((item["id"], item["snippet"]["channelId"]))

    return videos


def get_first_comment_and_author(api_key, video_id):
    youtube = build("youtube", "v3", developerKey=api_key)
    response = youtube.commentThreads().list(
        part="snippet",
        videoId=video_id,
        maxResults=1,
        textFormat="plainText"
    ).execute()
    if response.get("items"):
        comment_snippet = response["items"][0]["snippet"]["topLevelComment"]["snippet"]
        text = comment_snippet["textDisplay"]
        author_id = comment_snippet["authorChannelId"]["value"]
        return text, author_id
    return None, None

def get_transcript_text(video_id):
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=["ko", "en"])
        return " ".join([entry["text"] for entry in transcript])
    except Exception as e:
        print("âŒ ìŠ¤í¬ë¦½íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:", e)
        return None

def get_description(youtube, video_id):
    try:
        response = youtube.videos().list(part="snippet", id=video_id).execute()
        return response["items"][0]["snippet"]["description"]
    except Exception as e:
        print("âŒ ë”ë³´ê¸°ë€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:", e)
        return None

def ask_sonar_from_comment(comment_text, source_name=""):
    headers = {
        "Authorization": f"Bearer {SONAR_API_KEY}",
        "Content-Type": "application/json"
    }

    prompt_prefix = {
        "ê³ ì •ëŒ“ê¸€": "ì´ ëŒ“ê¸€ì€ ìœ íŠœë¸Œ ìš”ë¦¬ ì˜ìƒì˜ ê³ ì • ëŒ“ê¸€ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.",
        "ë”ë³´ê¸°ë€": "ì´ í…ìŠ¤íŠ¸ëŠ” ìœ íŠœë¸Œ ì˜ìƒì˜ ë”ë³´ê¸°ë€ì…ë‹ˆë‹¤. ë©”ë‰´/ì¬ë£Œì™€ ë¬´ê´€í•˜ê±°ë‚˜ ê´‘ê³ , ì œí’ˆ í™ë³´, ë§í¬ ì•ˆë‚´ê°€ ì£¼ëœ ê²½ìš° ë¶„ì„í•˜ì§€ ë§ê³  'ë¶„ì„ ë¶ˆê°€'ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”.",
        "ìŠ¤í¬ë¦½íŠ¸": "ì´ í…ìŠ¤íŠ¸ëŠ” ìœ íŠœë¸Œ ìë§‰(ìŠ¤í¬ë¦½íŠ¸)ì…ë‹ˆë‹¤."
    }

    prompt = f"""{prompt_prefix.get(source_name, 'ì´ í…ìŠ¤íŠ¸ëŠ” ìš”ë¦¬ ì˜ìƒì˜ ì¼ë¶€ì…ë‹ˆë‹¤.')} 
ë‚´ìš©ì—ì„œ ìš”ë¦¬ ë©”ë‰´ ì´ë¦„ê³¼ ì¬ë£Œë“¤ì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. 
ë‹¤ì§„/ê¹/ì‚¶ì€ ë“±ì˜ ìˆ˜ì‹ì–´ëŠ” ì œê±°í•˜ê³  ì¬ë£Œ ì´ë¦„ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”. Ex) ê¹ë§ˆëŠ˜ â†’ ë§ˆëŠ˜, ë‹¤ì§„ ìª½íŒŒ â†’ ìª½íŒŒ
ìš”ë¦¬ë‚˜ ì¬ë£Œê°€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šê³ , ì œí’ˆ ì„¤ëª…ì´ë‚˜ í™ë³´ë§Œ ìˆë‹¤ë©´ ë°˜ë“œì‹œ `"Only ì œí’ˆ ì„¤ëª… OR í™ë³´"`ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
- ë§Œì•½ ì—¬ëŸ¬ ì„¹ì…˜(ì˜ˆ: ë¸Œë¼ì¸, ì½©í”¼, ë“œë ˆì‹±)ì´ ì¡´ì¬í•˜ë”ë¼ë„ ë©”ë‰´ëŠ” í•˜ë‚˜ì´ë©°, ëª¨ë“  ì„¹ì…˜ì˜ ì¬ë£Œë¥¼ ì¤‘ë³µ ì—†ì´ í†µí•©í•´ì„œ "ì¬ë£Œ"ì— í¬í•¨í•´ì£¼ì„¸ìš”.


ë‚´ìš©:
{comment_text}

í˜•ì‹:
{{
  "ë©”ë‰´": "ë©”ë‰´ ì´ë¦„",
  "ì¬ë£Œ": ["ì¬ë£Œ1", "ì¬ë£Œ2", ...]
}}"""

    payload = {
        "model": "sonar-reasoning",
        "messages": [
            {"role": "system", "content": "ë„Œ ìš”ë¦¬ ì˜ìƒ ë¶„ì„ ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "search": False
    }
    response = requests.post("https://api.perplexity.ai/chat/completions", headers=headers, json=payload)

    if response.status_code == 200 and response.content.strip():
        try:
            return response.json()["choices"][0]["message"]["content"]
        except Exception as e:
            print("âŒ Sonar ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜:", e)
            return None
    else:
        print("âŒ Sonar ì‘ë‹µ ì—†ìŒ ë˜ëŠ” ì‹¤íŒ¨:", response.status_code)
        return None

# âœ… ì‹¤í–‰
videos_all = get_video_ids_and_channel(API_KEY, CHANNEL_ID, max_results=50)
videos = videos_all[40:50]

youtube = build("youtube", "v3", developerKey=API_KEY)
initialize_js_file_if_needed()

for idx, (video_id, uploader_id) in enumerate(videos, start=1):
    print(f"\nğŸ“Œ ì˜ìƒ {idx}ë²ˆ: https://youtu.be/{video_id}")
    video_url = f"https://youtu.be/{video_id}"
    video_response = youtube.videos().list(part="snippet", id=video_id).execute()
    snippet = video_response["items"][0]["snippet"]
    uploader_name = snippet["channelTitle"]
    upload_date = snippet["publishedAt"][:10]
    comment, author_id = get_first_comment_and_author(API_KEY, video_id)

    # ìˆœì„œ: ê³ ì •ëŒ“ê¸€ â†’ ë”ë³´ê¸°ë€ â†’ ìŠ¤í¬ë¦½íŠ¸
    sources = [
        ("ê³ ì •ëŒ“ê¸€", comment if author_id == uploader_id else None),
        ("ë”ë³´ê¸°ë€", get_description(youtube, video_id)),
        ("ìŠ¤í¬ë¦½íŠ¸", get_transcript_text(video_id))
    ]

    print("ğŸ” ë¶„ì„ ìˆœì„œ: ê³ ì •ëŒ“ê¸€ â†’ ë”ë³´ê¸°ë€ â†’ ìŠ¤í¬ë¦½íŠ¸")

    for source_name, text in sources:
        print(f"â­ï¸ í˜„ì¬ ë‹¨ê³„: {source_name} í™•ì¸ ì¤‘...")
        if not text:
            print(f"ğŸš« {source_name} ì—†ìŒ ë˜ëŠ” í™•ì¸ ë¶ˆê°€ â†’ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™")
            continue
        print(f"ğŸ“„ {source_name} ë¶„ì„ ì‹œë„")
        result = ask_sonar_from_comment(text, source_name)
        print(f"ğŸ§  Sonar ì‘ë‹µ ({source_name}):\n{result}")

        parsed = extract_json_block(result)
        if parsed:
            parsed["ì¶œì²˜"] = source_name
            append_to_js(parsed, video_url, uploader_name, upload_date)
            break
        else:
            print(f"âš ï¸ {source_name} ë¶„ì„ ì‹¤íŒ¨ â†’ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™")


    print("-" * 60)

finalize_js_file()
